{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modules imported\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "import random\n",
    "import time\n",
    "import tensorflow\n",
    "import datetime\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # 3 = INFO, WARNING, and ERROR messages are not printed\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import FileLink\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns \n",
    "%matplotlib inline\n",
    "from IPython.display import display, Image\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "#importing all the necessary modules/packages for this project\n",
    "print(\"modules imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPath = 'C:/Users/Sarwar/Downloads/Stanford40/JPEGImages' #where the image set is located\n",
    "IMG_SIZE = 224\n",
    "batch_size = 300\n",
    "nb_epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_img(img): #this labels the images\n",
    "    word_label = img.split('_')[0]\n",
    "    next_word = img.split('_')[1]\n",
    "    if len(img.split('_')) > 2:\n",
    "        word_3 = img.split('_')[2]\n",
    "    else:\n",
    "        word_3 = 'nada' \n",
    "    if len(img.split('_')) > 3:\n",
    "        word_4 = img.split('_')[3]\n",
    "    else:\n",
    "        word_4 = 'nada'\n",
    "        \n",
    "    label = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    i = 0\n",
    "    # 40-labels conversion ladder \n",
    "    if word_label == 'applauding': i = 0\n",
    "    elif word_label == 'blowing': i = 1\n",
    "    elif word_label == 'brushing': i = 2\n",
    "    elif word_label == 'cleaning': i = 3\n",
    "    elif word_label == 'climbing': i = 4\n",
    "    elif word_label == 'cooking': i = 5\n",
    "    elif word_label == 'cutting' and next_word == 'trees': i = 6\n",
    "    elif word_label == 'cutting': i = 7\n",
    "    elif word_label == 'drinking': i = 8\n",
    "    elif word_label == 'feeding': i = 9\n",
    "    #10\n",
    "    elif word_label == 'fishing': i = 10\n",
    "    elif word_label == 'fixing' and word_3 == 'bike': i = 11\n",
    "    elif word_label == 'fixing': i = 12\n",
    "    elif word_label == 'gardening': i = 13\n",
    "    elif word_label == 'holding': i = 14\n",
    "    elif word_label == 'jumping': i = 15\n",
    "    elif word_label == 'looking' and word_4 == 'microscope': i = 16\n",
    "    elif word_label == 'looking': i = 17\n",
    "    elif word_label == 'playing' and next_word == 'guitar': i = 18\n",
    "    elif word_label == 'playing': i = 19\n",
    "    #20\n",
    "    elif word_label == 'pouring': i = 20\n",
    "    elif word_label == 'pushing': i = 21\n",
    "    elif word_label == 'reading': i = 22\n",
    "    elif word_label == 'phoning': i = 23\n",
    "    elif word_label == 'riding' and word_3 == 'bike': i = 24\n",
    "    elif word_label == 'riding': i = 25\n",
    "    elif word_label == 'rowing': i = 26\n",
    "    elif word_label == 'running': i = 27\n",
    "    elif word_label == 'shooting': i = 28\n",
    "    elif word_label == 'smoking': i = 29\n",
    "    #30\n",
    "    elif word_label == 'taking': i = 30\n",
    "    elif word_label == 'texting': i = 31\n",
    "    elif word_label == 'throwing': i = 32\n",
    "    elif word_label == 'using': i = 33\n",
    "    elif word_label == 'walking': i = 34\n",
    "    elif word_label == 'washing': i = 35\n",
    "    elif word_label == 'watching': i = 36\n",
    "    elif word_label == 'waving': i = 37\n",
    "    elif word_label == 'writing' and word_4 == 'board': i = 38\n",
    "    elif word_label == 'writing': i = 39\n",
    "    #40\n",
    "    label[i] = 1\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_data_x(): #creates the x-variable of the training data\n",
    "    training_data_x = []\n",
    "    for img in tqdm(os.listdir(trainPath)):\n",
    "        #label = label_img(img)\n",
    "        path = os.path.join(trainPath,img)\n",
    "        img = cv2.imread(path)\n",
    "        img = tensorflow.keras.preprocessing.image.load_img(path, target_size=[IMG_SIZE, IMG_SIZE])\n",
    "        training_data_x.append([np.array(img)])\n",
    "    np.save('train_data_x.npy', training_data_x)\n",
    "    return training_data_x\n",
    "\n",
    "def create_train_data_y(): #creates the y-variable of the training data\n",
    "    training_data_y = []\n",
    "    for img in tqdm(os.listdir(trainPath)):\n",
    "        label = label_img(img)\n",
    "        #path = os.path.join(trainPath,img)\n",
    "        #img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "        #img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "        training_data_y.append([label])\n",
    "    np.save('train_data_y.npy', training_data_y)\n",
    "    return training_data_y\n",
    "\n",
    "#def process_test_data():\n",
    "#lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing my $H!T works so far\n",
    "txt = \"waving_hands_182.jpg\"\n",
    "label_img(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    return tensorflow.keras.applications.MobileNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 9532/9532 [05:55<00:00, 26.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 9532/9532 [00:43<00:00, 220.83it/s]\n"
     ]
    }
   ],
   "source": [
    "#DON'T TOUCH DIS ONE BOY\n",
    "x_train, y_train = create_train_data_x(), create_train_data_y()\n",
    "# If you have already created the dataset:\n",
    "x_train, y_train = np.load('train_data_x.npy'), np.load('train_data_y.npy')\n",
    "X = np.array(x_train).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "Y = [y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_7 to have shape (224, 224, 3) but got array with shape (224, 224, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-ea9af6100195>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m               \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# how will we calculate our \"error.\" Neural network aims to minimize loss.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m               metrics=['accuracy'])  # what to track\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m '''\n\u001b[0;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'action_stanford.model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    774\u001b[0m         \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 776\u001b[1;33m         shuffle=shuffle)\n\u001b[0m\u001b[0;32m    777\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m     \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle)\u001b[0m\n\u001b[0;32m   2380\u001b[0m         \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2381\u001b[0m         \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2382\u001b[1;33m         exception_prefix='input')\n\u001b[0m\u001b[0;32m   2383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2384\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    360\u001b[0m                 \u001b[1;34m'Error when checking '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mexception_prefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m                 ' but got array with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    363\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected input_7 to have shape (224, 224, 3) but got array with shape (224, 224, 1)"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.compile(optimizer='adam',  # Good default optimizer to start with\n",
    "              loss='sparse_categorical_crossentropy',  # how will we calculate our \"error.\" Neural network aims to minimize loss.\n",
    "              metrics=['accuracy'])  # what to track\n",
    "model.fit(X, Y, epochs=nb_epoch)  # train the model\n",
    "'''\n",
    "model.save('action_stanford.model')\n",
    "new_model = tf.keras.models.load_model('action_stanford.model')\n",
    "predictions = new_model.predict(x_test)\n",
    "print(predictions)\n",
    "print(np.argmax(predictions[0]))\n",
    "plt.imshow(x_test[0], cmap=plt.cm.binary)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
